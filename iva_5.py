# -*- coding: utf-8 -*-
"""iva_5_task3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ISmGIvBcVil4hpSorgOqQHnkhZaCl0Pw
"""

pip install kaggle

import os
os.system("kaggle datasets download -d jangedoo/utkface-new")

import zipfile

# Assuming the downloaded file is in the current directory
with zipfile.ZipFile("utkface-new.zip", 'r') as zip_ref:
    zip_ref.extractall("utkface_new")

dataset_path = os.path.abspath("utkface_new")
print("Path to dataset files:", dataset_path)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
import os

# Load dataset
image_directory = '/content/utkface_new/UTKFace'
image_files = os.listdir(image_directory)

age_labels = []
gender_labels = []
image_paths = []

for file in image_files:
    parts = file.split('_')
    age = int(parts[0])
    gender = int(parts[1])
    age_labels.append(age)
    gender_labels.append(gender)
    image_paths.append(os.path.join(image_directory, file))
# Create a DataFrame for easy manipulation
df = pd.DataFrame({
    'image_path': image_paths,
    'age': age_labels,
    'gender': gender_labels
})

# Check dataset structure
df.head()

import cv2
from google.colab.patches import cv2_imshow

# Load the Haar Cascade for face detection
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

# Function to detect faces in images and crop the face region
def detect_and_crop_face(image_path):
    image = cv2.imread(image_path)
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)

    if len(faces) == 0:
        return None  # No face detected
    #cv2_imshow(image)
    for (x, y, w, h) in faces:
        cropped_face = gray[y:y+h, x:x+w]
        return cropped_face

    return None

# Test with one image from the dataset
cropped_face = detect_and_crop_face(df['image_path'].iloc[2])
if cropped_face is not None:
    cv2_imshow(cropped_face)

from skimage.feature import local_binary_pattern

# Function to extract geometric features (example: distance between eyes)
def extract_geometric_features(face_image):
    eyes_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')
    eyes = eyes_cascade.detectMultiScale(face_image)

    if len(eyes) >= 2:
        # Calculate distance between the first two eyes detected
        (x1, y1, w1, h1), (x2, y2, w2, h2) = eyes[:2]
        eye_distance = np.linalg.norm(np.array([x1, y1]) - np.array([x2, y2]))
        return eye_distance
    return None

# Function to extract texture features using Local Binary Patterns (LBP)
def extract_texture_features(face_image):
    radius = 1  # Radius for LBP
    n_points = 8 * radius  # Number of points for LBP
    lbp = local_binary_pattern(face_image, n_points, radius, method="uniform")

    # Create a histogram of the LBP values
    (hist, _) = np.histogram(lbp.ravel(),
                             bins=np.arange(0, n_points + 3),
                             range=(0, n_points + 2))

    # Normalize the histogram
    hist = hist.astype("float")
    hist /= (hist.sum() + 1e-6)  # Avoid division by zero

    return hist

# Example usage:
#geometric_feature = extract_geometric_features(cropped_face)
texture_feature = extract_texture_features(cropped_face)

#print(f"Geometric Feature (Eye Distance): {geometric_feature}")
print(f"texture_Feature: {texture_feature}")

import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from skimage.feature import local_binary_pattern
import random
import dlib
from scipy.spatial import distance

# Load sample dataset
def load_sample_dataset(df, n_samples=100):
    # Randomly select n_samples from the dataset
    return df.sample(n_samples, random_state=42)
# Function to process a sample dataset and collect features
def analyze_features(df):
    features = []
    # Load a sample dataset of 100 images
    sample_df = load_sample_dataset(df, n_samples=100)
    for idx, row in sample_df.iterrows():
        face = detect_and_crop_face(row['image_path'])
        if face is not None:
            # Extract texture features using LBP
            texture_features = extract_texture_features(face)
            texture_sum = np.sum(texture_features)  # Example metric
            # Extract geometric features (mock values)
            geometric_features = extract_geometric_features(face)
            eye_distance = geometric_features
            features.append({
                'gender': 'Male' if row['gender'] == 1 else 'Female',
                'texture_sum': texture_sum,
                #'jawline_width': jawline_width,
                'eye_distance': eye_distance
            })
    return pd.DataFrame(features)
# Function to analyze the features and determine thresholds
def determine_thresholds(features_df):
    # Separate features by gender
    male_features = features_df[features_df['gender'] == 'Male']
    female_features = features_df[features_df['gender'] == 'Female']
    # Calculate thresholds for texture sum
    texture_threshold = (male_features['texture_sum'].mean() + female_features['texture_sum'].mean()) / 2
    # Calculate thresholds for jawline width and eye distance
    #jawline_threshold = (male_features['jawline_width'].mean() + female_features['jawline_width'].mean()) / 2
    eye_distance_threshold = (male_features['eye_distance'].mean() + female_features['eye_distance'].mean()) / 2
    return texture_threshold, eye_distance_threshold

# Run the feature analysis
features_df = analyze_features(df)
texture_threshold, eye_distance_threshold = determine_thresholds(features_df)

print(f"Texture Sum Threshold: {texture_threshold:.4f}")
#print(f"Jawline Width Threshold: {jawline_threshold:.4f}")
print(f"Eye Distance Threshold: {eye_distance_threshold:.4f}")

# Visualize distributions (optional)
plt.figure(figsize=(12, 8))
plt.subplot(3, 1, 1)
plt.hist(features_df['texture_sum'][features_df['gender'] == 'Male'], bins=15, alpha=0.5, label='Male', color='blue')
plt.hist(features_df['texture_sum'][features_df['gender'] == 'Female'], bins=15, alpha=0.5, label='Female', color='orange')
plt.axvline(texture_threshold, color='red', linestyle='dashed', linewidth=1)
plt.title('Texture Sum Distribution')
plt.xlabel('Texture Sum')
plt.ylabel('Frequency')
plt.legend()


plt.subplot(3, 1, 2)
plt.hist(features_df['eye_distance'][features_df['gender'] == 'Male'], bins=15, alpha=0.5, label='Male', color='blue')
plt.hist(features_df['eye_distance'][features_df['gender'] == 'Female'], bins=15, alpha=0.5, label='Female', color='orange')
plt.axvline(eye_distance_threshold, color='red', linestyle='dashed', linewidth=1)
plt.title('Eye Distance Distribution')
plt.xlabel('Eye Distance')
plt.ylabel('Frequency')
plt.legend()

plt.tight_layout()
plt.show()

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Function to classify gender based on features and thresholds
def classify_gender(texture_sum, eye_distance):
    if texture_sum > texture_threshold or eye_distance > eye_distance_threshold:
        return 1  # Male
    else:
        return 0  # Female


# Process dataset and classify gender
y_true = []
y_pred = []
df1=load_sample_dataset(df, n_samples=5000)
for idx, row in df1.iterrows():
    face = detect_and_crop_face(row['image_path'])

    if face is not None:
        # Extract features
        texture_features = extract_texture_features(face)
        texture_sum = np.sum(texture_features)
        geometric_features = extract_geometric_features(face)

        if geometric_features is not None:
            eye_distance = geometric_features
            # Classify gender based on extracted features
            predicted_gender = classify_gender(texture_sum, eye_distance)
            # Append true and predicted labels
            y_true.append(row['gender'])
            y_pred.append(predicted_gender)
# Evaluation
accuracy = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)
f1 = f1_score(y_true, y_pred)
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")



















